postgresql:
  enabled: false

concourse:
  image: vito/concourse
  imageDigest: sha256:8ec0fe6652be3bf152ae196f6612fac2fe035804076caa6b107a88a1bef432fd

  secrets:
    teamAuthorizedKeys:
    - team: monitoring-hush-house
      key: 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDP5oT2CUJgRP55iNQD7NK4JzxRHSKstRXAV9EJw6O2Iaf9D9foHOaYNpgeIrRW4sbGvucLMhOBchp7yOhPTxn9jCUIGQttAWnFWW9SeHYOwPmbC30ggIIKmUQ/oWC6Xxou+KPotmqkKv+YyxNh8otTY5Sbz8VodEVqYR4hgXqunbSlcYJdMJqt6w0R319INdd898o6MbRrO5tj2I0ej8/Ct/n8Ijliawj3Mlm3g3w0O31C/Aj9jpEyvt+7JfcRWeJ1VcEnDsy4/UTqLh8P46LX/vzPQoPp54qrSaMcN7/1ylqn8XG5g+QWH4rmyJhH+0d1bt4v05M8b/UuHdXHgXVDMYyIFbvz2hRdhX7ZSHtP48e1B9t1S5Uo9gPG4D0jkWdMkpQf8/b4PXNF4nmBdKcWp9DqfYZOBMM17ZckOoWTnIORuZ/Xzgk1k11k0yAwRDxEksQuTSQexf5zxnku3ZediR5CwdbY9w4NiYB0DVCK7ktPi7Yg6RPrDgfALdB4vIg6jcWI3xw0ot2XVpZ2MGmUxL+ZlsymYncQ5p3pHRbznWbR2piniCa4rbE/KP0zFTDrNIMp2433nI0q5P1WbNuOQkL/XOIFkNr6f81ra9XJZWsV4Ytozivi5cg7hiPgCgxfUpnAQ+7NsSFYnV/gmmLjKUVCsdEwxqH5IxlxMYJqlQ=='

  postgresql:
    enabled: false

  web:
    annotations:
      rollingUpdate: "3"
    livenessProbe:
      # XXX(vito): for builds bigint migration - comment out when no longer
      # needed
      initialDelaySeconds: 600
    replicas: 2
    env:
    - name: CONCOURSE_X_FRAME_OPTIONS
      value: ""
    nodeSelector: { cloud.google.com/gke-nodepool: generic-1 }
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            topologyKey: kubernetes.io/hostname
            labelSelector:
              matchLabels:
                app: ci-web
                release: ci
    sidecarContainers:
      - name: oc-agent
        image: omnition/opencensus-agent:0.1.11
        volumeMounts:
          - name: oc-agent-config
            mountPath: /etc/config
        command: ["/ocagent_linux", "--config=/etc/config/config.yml"]
      - name: wavefront-proxy
        image: wavefronthq/proxy:7.2
        env:
        - name: WAVEFRONT_URL
          value: "https://vmware.wavefront.com/api/"
        - name: WAVEFRONT_PROXY_ARGS
          value: "--traceListenerPorts 30000"
        - name: WAVEFRONT_TOKEN
          valueFrom:
            secretKeyRef:
              name: wavefront-proxy
              key: token
    additionalVolumes:
      - name: dsdsocket
        hostPath:
          path: /var/run/datadog
      - name: oc-agent-config
        configMap:
          name: ocagent-config
    additionalVolumeMounts:
      - name: dsdsocket
        mountPath: /var/run/datadog
    service:
      api:
        type: LoadBalancer
        loadBalancerIP: 34.69.51.78
      workerGateway:
        type: LoadBalancer
        loadBalancerIP: 34.69.51.78
    resources:
      requests:
        cpu: 1500m
        memory: 1Gi
      limits:
        cpu: 1500m
        memory: 1Gi

  persistence:
    worker:
      storageClass: ssd
      size: 750Gi

  worker:
    replicas: 8
    annotations:
      manual-update-revision: "1"
    terminationGracePeriodSeconds: 3600
    livenessProbe:
      periodSeconds: 60
      failureThreshold: 10
      timeoutSeconds: 45
    nodeSelector: { cloud.google.com/gke-nodepool: ci-workers }
    hardAntiAffinity: true
    env:
    - name: CONCOURSE_GARDEN_NETWORK_POOL
      value: "10.254.0.0/16"
    - name: CONCOURSE_GARDEN_MAX_CONTAINERS
      value: "500"
    - name: CONCOURSE_GARDEN_DENY_NETWORK
      value: "169.254.169.254/32"
    resources:
      limits:   { cpu: 7500m, memory: 14Gi }
      requests: { cpu: 0m,    memory: 0Gi  }

  concourse:
    web:
      auth:
        mainTeam:
          localUser: admin
          github:
            team: concourse:Pivotal
        github:
          enabled: true
      # so pipeline-operator ended up with two permissions
      # - RerunJobBuild
      # - CheckResource
      # which will be granted to concourse:contributors for
      # operating PR pipeline
      configRBAC: |
        member:
        - AbortBuild
        - CreateJobBuild
        - PauseJob
        - UnpauseJob
        - ClearTaskCache
        - UnpinResource
        - SetPinCommentOnResource
        - CheckResourceWebHook
        - CheckResourceType
        - EnableResourceVersion
        - DisableResourceVersion
        - PinResourceVersion
        - PausePipeline
        - UnpausePipeline
      bindPort: 80
      clusterName: ci
      containerPlacementStrategy: limit-active-tasks
      streamingArtifactsCompression: zstd
      maxActiveTasksPerWorker: 5
      enableGlobalResources: true
      enableAcrossStep: true
      encryption: { enabled: true }
      externalUrl: https://ci.concourse-ci.org
      kubernetes:
        keepNamespaces: false
        enabled: false
        createTeamNamespaces: false
      metrics:
        attribute: "environment:ci"
      tracing:
        jaegerEndpoint: http://127.0.0.1:14268/api/traces
      vault:
        enabled: true
        url: https://vault.vault.svc.cluster.local:8200
        sharedPath: shared
        authBackend: "cert"
        useCaCert: true
      letsEncrypt: { enabled: true, acmeURL: "https://acme-v02.api.letsencrypt.org/directory" }
      tls: { enabled: true, bindPort: 443 }
      datadog:
        enabled: true

        # horrible hack; we need a proper way to configure unix sockets
        agentHost: unix
        agentPort: ///var/run/datadog/dsd.socket
      postgres:
        host: 34.69.204.254
        database: atc
        sslmode: verify-ca
    worker:
      rebalanceInterval: 2h
      baggageclaim: { driver: overlay }
      healthcheckTimeout: 40s
      # runtime: containerd
      # containerd:
      #   networkPool: "10.254.0.0/16"
      #   maxContainers: "500"
      #   restrictedNetworks:
      #     - "169.254.169.254/32"

datadog:
  datadog:
    useDogStatsDSocketVolume: true

kubeStateMetrics:
  enabled: false
